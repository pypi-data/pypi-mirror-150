class FirstOrderMM(AbstractFactor):
    """Implements a first-order homogeneous Markov Model.
    """
    def __init__(self, state_priors, trans_probs):
        """Create a |FirstOrderHMM|.
        
        Parameters
        ----------
        state_priors : |ArrayFactor|
            Probabilities of starting in any state
       
        trans_probs : |MatrixFactor|
            |MatrixFactor| describing transition probabilities from each state
            (first index) to each other state (second index).
        """
        assert len(state_priors) == len(trans_probs)
        self.num_states = len(state_priors)
        self.state_priors   = state_priors
        self.trans_probs    = trans_probs
    
    def __str__(self):
        return repr(self)
   
    def __repr__(self):
        return "<%s %s states>" % (self.__class__.__name__, self.num_states)
    
    def probability(self, sequence):
        """Compute the probability of observing a sequence.
        This number is likely to undeflow for long sequences.

        Parameters
        ----------
        sequence : numpy.ndarray
            Sequence of observations
        
        Returns
        -------
        float
            Probability of sequence of emissions
        """
        return numpy.exp(self.logprob(sequence))
    
    def logprob(self, emission):
        """Compute the log probability of observing a sequence of sequence.

        Parameters
        ----------
        sequence : numpy.ndarray
            Sequence of observations
        
        Returns
        -------
        float
            log probability of sequence of sequence
        """
        return self.fast_forward(emission)

    def forward(self, sequence):
        """Calculates the log-probability of observing a sequence,
        regardless of the state sequence, using the Forward Algorithm. This
        implementation also retains intermediate state information useful in
        posterior decoding or Baum-Welch training.
        
        Numerical underflows are prevented by scaling probabilities at each step,
        following the procedure given in Rabiner (1989), "A Tutorial on Hidden
        Markov Models and Selected Applications in Speech Recognition"
        
        Vectorized implementation from Wikipedia (2014-02-20):
        http://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm
        
        Parameters
        ----------
        sequence : numpy.ndarray
            Sequence of observations
        
        Returns
        -------
        float
            log probability of sequence of sequence
        
        numpy.ndarray
            [time x num_states] Array representing  scaled forward algorithm vector,
            indicating the forward probability of being in each state at time T,
            given the model and the observation trajectory from t = 0 to t = T
        
        numpy.ndarray
            [time x 1] Array of scaling constants used at each step as described in Rabiner 1989.
            The sum of the log of these equals the log probability of the observation sequence.
        """
        total_logprob, scaled_forward, _, scale_factors, _ = self.forward_backward(sequence, calc_backward=False)
        return total_logprob, scaled_forward, scale_factors
    
    def forward_backward(self, sequence, calc_backward=True):
        """Calculates modified forward and backward algorithms for partially-observed sequences generated by Markov Models,
        as well as sufficient statistics useful in Baum-Welch calculations, all in factored and 
        vectorized forms. 
        
        Numerical underflows are prevented by scaling forward  probabilities at each
        step, following the procedure given in Rabiner (1989), "A Tutorial on Hidden
        Markov Models and Selected Applications in Speech Recognition"
        
        Vectorized implementation adapted from Wikipedia (2014-02-20):
        http://en.wikipedia.org/wiki/Forward%E2%80%93backward_algorithm
        but using scaling as described in Rabiner1989 and Durbin1998, rather
        than the Wikipedia article
        
        
        Parameters
        ----------
        sequence : numpy.ndarray
            Observation sequence, possibly a partially-observed sequence, with any unobserved state set to -1.
        
        calc_backward : bool, optional
            If True, perform backward pass and calculate Rabiner's ksi table
        
        
        Returns
        -------
        float
            log probability of sequence of sequence
        
        numpy.array
            Scaled forward algorithm vector of dim [time x num_states],
            indicating the forward probability of being in each state at time T,
            given the model and the observation trajectory from t = 0 to t = T

        numpy.ndarray
            Scaled backward algorithm vector of dim [time x num_states],
            indicating the backward probability of being in each state at time T,
            given the model and the observation trajectory from t = T to t = end

        numpy.ndarray
            [time x 1] Array of scaling constants used at each step as described in Rabiner 1989.
            The sum of the log of these equals the log probability of the observation sequence.
            
        numpy.ndarray
            [time x num_states x num_states] ksi table, as described in Rabiner 1989.
            At each time t, ksi[t,i,j] gives the posterior
            probability of transitioning from state i to state j. From this
            table it is trivial to derive the expected number of transitions 
            from state i to state j, or the posterior probability of being in
            state i or j at a given timepoint, by taking the appropriate sum.

        Notes
        -----
        This implementation casts everything to ``numpy.float128``. Whether this will
        actually force use of IEEE float128 depends on local C library implementations
        """
        # probability sequence indexed by timeslice. columns are end states
        scaled_forward = numpy.zeros((len(sequence), self.num_states))
        scale_factors  = numpy.ones(len(sequence))
        O = []
    
        # initialize as prior + likelihood of sequence
        scaled_forward[0, sequence[0]] = self.state_priors[sequence[0]]
        
        # can get underflows here from very improbable sequence
        #
        # can get nan for probability if f.sum() is 0, in other words, if a 
        # given observation is very improbable for all models and underflows 
        # for all models, then c = 0, and f/c = [nan,nan,...,nan]
        #
        # This then forces all future probabilities to be set to nan,
        # which messes up forward and backward calculations.
        # In this case, using HighPrecisionFirstOrderHMM will work,
        # but at a cost for speed
        for t in range(1, len(sequence)):
            if sequence[t] == -1:
                f = scaled_forward[t - 1, :].dot(self.trans_probs)
                c = f.sum()
                scaled_forward[t, :] = f / c
                scale_factors[t] = f
            else:
                f = (scaled_forward[t - 1, :] * self.trans_probs[sequence[t - 1], sequence[t]]).sum()
                scaled_forward[t, sequence[t]] = 1.0
                scale_factors[t] = f
        
        if calc_backward is True:
            # backward calc    
            scaled_backward = numpy.zeros((len(sequence), self.num_states))
            scaled_backward[-1, :] = 1.0 / scale_factors[-1] # <---- Wikipedia says not to scale final timestep; Rabiner & Durbin say to
            for t in range(len(sequence)-1)[::-1]:
                if sequence[t] == -1:
                    scaled_backward[t, :] = self.trans_probs.dot(scaled_backward[t + 1, :]) / scale_factors[t]
                else:
                    scaled_backward[t, sequence[t]] = (self.trans_probs[sequence[t], sequence[t + 1]] * scaled_backward[t + 1]).sum() / scale_factors[t]

            # scale factors cancel out,  returning Rabiner's ksi statistic
            ksi = scaled_forward[:-1, :, None]*scaled_backward[1:, None, :]*self.trans_probs[None, :, :]

        else:
            scaled_backward = None
            ksi = None

        if numpy.isnan(scale_factors).any():
            total_logprob = -numpy.Inf
        else:  
            total_logprob = numpy.log(scale_factors).sum()
    
        return total_logprob, scaled_forward, scaled_backward, scale_factors, ksi    
    
    def posterior_decode(self, partial_sequence):
        """Find the most probable a posteriori state for each unfilled observation in `partial_sequence`
        
         .. note::
            This objective is distinct
            from finding the most probable sequence of states for all sequence, as
            is given in Viterbi decoding. This alternative may be more appropriate
            when multiple paths have similar probabilities, making the most likely
            path dubious.

        
        Parameters
        ----------
        partial_sequence : numpy.ndarray
            Sequence of observations, with unobserved states set to -1
        
        Returns
        -------
        numpy.ndarray
            An array of dimension [t x 1] of the most likely states at each point t
        
        numpy.ndarray
            An array of dimension [t x k] of the posterior probability of being
            in state k at time t 
        """
        _, forward, backward, scale_factors, _  = self.forward_backward(partial_sequence)
        posterior_probs    = forward * backward * scale_factors
        most_likely_states = (posterior_probs).argmax(1)
        
        return most_likely_states, posterior_probs
    
    def generate(self, length):
        """Generates a random sequence of states and sequence from the HMM
        
        Parameters
        ----------
        length : int
            Length of sequence to generate
        
        
        Returns
        -------
        numpy.ndarray
            Array of dimension [t x 1] indicating the MM state at each timestep
        """
        sequence = []
        
        sequence.append(self.state_priors.generate())
        
        for i in range(1, length):
            new_state = self.trans_probs.generate(sequence[i-1])
            sequence.append(new_state)
        
        return numpy.array(sequence).astype(int)

    def sample(self, partial_sequence):
        """Probabilistically sample state sequences from the HMM using a modified
        Viterbi algorithm, given a set of observations. This may be used to test
        the reliability of a Viterbi decoding, or of subregions of the Viterbi
        decoding. 
        
        See Durbin1997 ch 4.3

        Parameters
        ----------
        sequence : numpy.ndarray
            Sequence of observations
        
        Returns
        -------
        numpy.ndarray
            A sequence of states, sampled according to its probability under
            the model
        
        float
            joint log probability of sequence of sequence
            and the returned state sequence
        """
        raise NotImplementedError("FirstOrderHMM.sample() is not yet implemented")
    
    def viterbi(self, sequence, verbose=False):
        """Finds the most likely state sequence underlying a set of sequence
        using the Viterbi algorithm. Also returns the natural log probability
        of that state sequence.
        
        See http://en.wikipedia.org/wiki/Viterbi_algorithm
        
        Parameters
        ----------
        sequence : numpy.ndarray
            Partial sequence of states, with unobserved states set to -1
       
        verbose : bool
            If True, the dictionary of log-probabilities at 
            the final state is returned in addition to the
            total log probability (Default: False)


        Returns
        ------
        numpy.ndarray
            Decoded labels for each position in sequence[start:end]
                            
        float
            joint log probability of sequence of sequence[start:end]
            and the decoded state sequence
        
        dict
            dict[state] = log probability of final symbol
            being in that state
        """
        T = numpy.log(self.trans_probs.data)

        state_dict = { K : [K] for K in range(self.num_states) }
        if sequence[0] == -1:
            prev_probs = copy.deepcopy(self.state_priors.data)
        else:
            prev_probs = numpy.zeros(self.num_states)
            prev_probs[sequence[0]] = 1.0

        for n, t in enumerate(sequence):
            if  sequence[t] == -1:
                new_state_dict = {}
                current_probs  = T + prev_probs[:, None]
                new_probs = current_probs.max(0)
            else:
                new_probs = numpy.zeros_like(new_probs)
                new_probs[sequence[t]] = 1.0

            new_state_dict = { X : state_dict[current_probs[:, X].argmax()] + [X] \
                                   for X in range(self.num_states) }

            prev_probs = new_probs
            state_dict = new_state_dict
        
        final_label   = prev_probs.argmax()
        total_logprob = prev_probs.max()
        states = numpy.array(state_dict[final_label])
        if verbose is False:
            return states, total_logprob
        else:
            return states, total_logprob, state_dict

