{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a3a084-31c7-49e1-9a87-8c3f9a7ce484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106, 100, 100, 3) (106, 4, 4) 138.88887889922103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-09 11:40:13.213550: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# Quick run cell\n",
    "import os, sys\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "if not os.path.exists('tiny_nerf_data.npz'):\n",
    "    !wget http://cseweb.ucsd.edu/~viscomp/projects/LF/papers/ECCV20/nerf/tiny_nerf_data.npz\n",
    "\n",
    "data = np.load('tiny_nerf_data.npz')\n",
    "images = data['images']\n",
    "poses = data['poses']\n",
    "focal = data['focal']\n",
    "H, W = images.shape[1:3]\n",
    "print(images.shape, poses.shape, focal)\n",
    "\n",
    "testimg, testpose = images[101], poses[101]\n",
    "images = images[:100,...,:3]\n",
    "poses = poses[:100]\n",
    "\n",
    "\n",
    "def posenc(x):\n",
    "  rets = [x]\n",
    "  for i in range(L_embed):\n",
    "    for fn in [tf.sin, tf.cos]:\n",
    "      rets.append(fn(2.**i * x))\n",
    "  return tf.concat(rets, -1)\n",
    "\n",
    "L_embed = 6\n",
    "embed_fn = posenc\n",
    "# L_embed = 0\n",
    "# embed_fn = tf.identity\n",
    "\n",
    "def init_model(D=8, W=256):\n",
    "    relu = tf.keras.layers.ReLU()    \n",
    "    dense = lambda W=W, act=relu : tf.keras.layers.Dense(W, activation=act)\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(3 + 3*2*L_embed)) \n",
    "    outputs = inputs\n",
    "    for i in range(D):\n",
    "        outputs = dense()(outputs)\n",
    "        if i%4==0 and i>0:\n",
    "            outputs = tf.concat([outputs, inputs], -1)\n",
    "    outputs = dense(4, act=None)(outputs)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_rays(H, W, focal, c2w):\n",
    "    i, j = tf.meshgrid(tf.range(W, dtype=tf.float32), tf.range(H, dtype=tf.float32), indexing='xy')\n",
    "    dirs = tf.stack([(i-W*.5)/focal, -(j-H*.5)/focal, -tf.ones_like(i)], -1)\n",
    "    rays_d = tf.reduce_sum(dirs[..., np.newaxis, :] * c2w[:3,:3], -1)\n",
    "    rays_o = tf.broadcast_to(c2w[:3,-1], tf.shape(rays_d))\n",
    "    return rays_o, rays_d\n",
    "\n",
    "\n",
    "\n",
    "def render_rays(network_fn, rays_o, rays_d, near, far, N_samples, rand=False):\n",
    "\n",
    "    def batchify(fn, chunk=1024*32):\n",
    "        return lambda inputs : tf.concat([fn(inputs[i:i+chunk]) for i in range(0, inputs.shape[0], chunk)], 0)\n",
    "    \n",
    "    # Compute 3D query points\n",
    "    z_vals = tf.linspace(near, far, N_samples) \n",
    "    if rand:\n",
    "      z_vals += tf.random.uniform(list(rays_o.shape[:-1]) + [N_samples]) * (far-near)/N_samples\n",
    "    pts = rays_o[...,None,:] + rays_d[...,None,:] * z_vals[...,:,None]\n",
    "    \n",
    "    # Run network\n",
    "    pts_flat = tf.reshape(pts, [-1,3])\n",
    "    pts_flat = embed_fn(pts_flat)\n",
    "    raw = batchify(network_fn)(pts_flat)\n",
    "    raw = tf.reshape(raw, list(pts.shape[:-1]) + [4])\n",
    "    \n",
    "    # Compute opacities and colors\n",
    "    sigma_a = tf.nn.relu(raw[...,3])\n",
    "    rgb = tf.math.sigmoid(raw[...,:3]) \n",
    "    \n",
    "    # Do volume rendering\n",
    "    dists = tf.concat([z_vals[..., 1:] - z_vals[..., :-1], tf.broadcast_to([1e10], z_vals[...,:1].shape)], -1) \n",
    "    alpha = 1.-tf.exp(-sigma_a * dists)  \n",
    "    weights = alpha * tf.math.cumprod(1.-alpha + 1e-10, -1, exclusive=True)\n",
    "    \n",
    "    rgb_map = tf.reduce_sum(weights[...,None] * rgb, -2) \n",
    "    depth_map = tf.reduce_sum(weights * z_vals, -1) \n",
    "    acc_map = tf.reduce_sum(weights, -1)\n",
    "\n",
    "    return rgb_map, depth_map, acc_map\n",
    "%matplotlib inline\n",
    "from ipywidgets import interactive, widgets\n",
    "\n",
    "\n",
    "trans_t = lambda t : tf.convert_to_tensor([\n",
    "    [1,0,0,0],\n",
    "    [0,1,0,0],\n",
    "    [0,0,1,t],\n",
    "    [0,0,0,1],\n",
    "], dtype=tf.float32)\n",
    "\n",
    "rot_phi = lambda phi : tf.convert_to_tensor([\n",
    "    [1,0,0,0],\n",
    "    [0,tf.cos(phi),-tf.sin(phi),0],\n",
    "    [0,tf.sin(phi), tf.cos(phi),0],\n",
    "    [0,0,0,1],\n",
    "], dtype=tf.float32)\n",
    "\n",
    "rot_theta = lambda th : tf.convert_to_tensor([\n",
    "    [tf.cos(th),0,-tf.sin(th),0],\n",
    "    [0,1,0,0],\n",
    "    [tf.sin(th),0, tf.cos(th),0],\n",
    "    [0,0,0,1],\n",
    "], dtype=tf.float32)\n",
    "\n",
    "\n",
    "def pose_spherical(theta, phi, radius):\n",
    "    c2w = trans_t(radius)\n",
    "    c2w = rot_phi(phi/180.*np.pi) @ c2w\n",
    "    c2w = rot_theta(theta/180.*np.pi) @ c2w\n",
    "    c2w = np.array([[-1,0,0,0],[0,0,1,0],[0,1,0,0],[0,0,0,1]]) @ c2w\n",
    "    return c2w\n",
    "\n",
    "\n",
    "model = keras.models.load_model('./model_checkpoint')\n",
    "\n",
    "N_samples = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed4ca17c-ca44-48b9-8938-59f5c8509561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83fd0b9343d446b6bade0e27ac9474d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NerfNav(cameraCoordinates={'theta': 100.0, 'phi': -30.0, 'radius': 4.0}, imageArray=[0, 0, 0, 0, 0, 0, 0, 0, 0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nerfviewer import NerfNav\n",
    "from IPython.display import display\n",
    "\n",
    "def render(h, w, focal, camera_tuple):\n",
    "    rays_o, rays_d = get_rays(h, w, focal, pose_spherical(**camera_tuple)[:3,:4])\n",
    "    return render_rays(model, rays_o, rays_d, near=2., far=6., N_samples=N_samples)\n",
    "\n",
    "NerfNav(render, H, W, focal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20ef5eaf-a5e4-4ff1-9360-bc6828b93542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9338f1e3d459444ba27ab71ae5abcfb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "NerfNav(cameraCoordinates={'theta': 100.0, 'phi': -30.0, 'radius': 4.0}, imageArray=[0, 0, 0, 0, 0, 0, 0, 0, 0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NerfNav(render, H, W, focal,keyframes=[{\"image\":[],\"coordinates\":{\"theta\":100,\"phi\":-30,\"radius\":4}}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbe4c4e0-7e1a-45f8-b098-57e8c8b0b264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'theta': 100, 'phi': -30, 'radius': 4}\n"
     ]
    }
   ],
   "source": [
    "print({\"theta\":100,\"phi\":-30,\"radius\":4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043a4bcd-46eb-4f98-b073-d732df4b12f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
