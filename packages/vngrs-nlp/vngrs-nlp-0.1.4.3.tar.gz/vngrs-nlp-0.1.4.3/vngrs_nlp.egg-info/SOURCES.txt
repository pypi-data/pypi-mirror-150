LICENSE
MANIFEST.in
README.md
pyproject.toml
setup.cfg
setup.py
vngrs_nlp.egg-info/PKG-INFO
vngrs_nlp.egg-info/SOURCES.txt
vngrs_nlp.egg-info/dependency_links.txt
vngrs_nlp.egg-info/entry_points.txt
vngrs_nlp.egg-info/requires.txt
vngrs_nlp.egg-info/top_level.txt
vnlp/__init__.py
vnlp/bin/__init__.py
vnlp/bin/vnlp.py
vnlp/dependency_parser/ReadMe.md
vnlp/dependency_parser/__init__.py
vnlp/dependency_parser/_utils.py
vnlp/dependency_parser/dependency_parser.py
vnlp/dependency_parser/resources/model_weights_except_word_embedding.pickle
vnlp/dependency_parser/resources/tokenizer_label.pickle
vnlp/dependency_parser/resources/tokenizer_word.pickle
vnlp/named_entity_recognizer/ReadMe.md
vnlp/named_entity_recognizer/__init__.py
vnlp/named_entity_recognizer/_utils.py
vnlp/named_entity_recognizer/named_entity_recognizer.py
vnlp/named_entity_recognizer/resources/model_weights.hdf5
vnlp/named_entity_recognizer/resources/tokenizer_char.pickle
vnlp/named_entity_recognizer/resources/tokenizer_label.pickle
vnlp/normalizer/ReadMe.md
vnlp/normalizer/__init__.py
vnlp/normalizer/_deasciifier.py
vnlp/normalizer/normalizer.py
vnlp/part_of_speech_tagger/ReadMe.md
vnlp/part_of_speech_tagger/__init__.py
vnlp/part_of_speech_tagger/_utils.py
vnlp/part_of_speech_tagger/part_of_speech_tagger.py
vnlp/part_of_speech_tagger/resources/model_weights_except_word_embedding.pickle
vnlp/part_of_speech_tagger/resources/tokenizer_pos_label.pickle
vnlp/part_of_speech_tagger/resources/tokenizer_tag.pickle
vnlp/part_of_speech_tagger/resources/tokenizer_word.pickle
vnlp/resources/non_breaking_prefixes_tr.txt
vnlp/resources/turkish_known_words_lexicon.txt
vnlp/resources/turkish_stop_words.txt
vnlp/resources/tdd-hunspell-tr-1.1.0/README.md
vnlp/resources/tdd-hunspell-tr-1.1.0/tr_TR.aff
vnlp/resources/tdd-hunspell-tr-1.1.0/tr_TR.dic
vnlp/sentence_splitter/ReadMe.md
vnlp/sentence_splitter/__init__.py
vnlp/sentence_splitter/sentence_splitter.py
vnlp/sentiment_analyzer/ReadMe.md
vnlp/sentiment_analyzer/__init__.py
vnlp/sentiment_analyzer/_utils.py
vnlp/sentiment_analyzer/sentiment_analyzer.py
vnlp/sentiment_analyzer/resources/model_weights_except_word_embedding.pickle
vnlp/sentiment_analyzer/resources/tokenizer_word.pickle
vnlp/stemmer_morph_analyzer/ReadMe.md
vnlp/stemmer_morph_analyzer/__init__.py
vnlp/stemmer_morph_analyzer/_melik_utils.py
vnlp/stemmer_morph_analyzer/_yildiz_analyzer.py
vnlp/stemmer_morph_analyzer/_yildiz_data_utils.py
vnlp/stemmer_morph_analyzer/stemmer_morph_analyzer.py
vnlp/stemmer_morph_analyzer/resources/ExactLookup.txt
vnlp/stemmer_morph_analyzer/resources/StemListWithFlags.txt
vnlp/stemmer_morph_analyzer/resources/StemListWithFlags_v2.txt
vnlp/stemmer_morph_analyzer/resources/Suffixes&Tags.txt
vnlp/stemmer_morph_analyzer/resources/model_weights.hdf5
vnlp/stemmer_morph_analyzer/resources/tokenizer_char.pickle
vnlp/stemmer_morph_analyzer/resources/tokenizer_tag.pickle
vnlp/stopword_remover/ReadMe.md
vnlp/stopword_remover/__init__.py
vnlp/stopword_remover/stopword_remover.py
vnlp/tokenizer/ReadMe.md
vnlp/tokenizer/__init__.py
vnlp/tokenizer/tokenizer.py
vnlp/tokenizer/word_embedding.matrix
vnlp/turkish_word_embeddings/ReadMe.md