{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelining for Whole Procedure after Crawling\n",
    "## Ver 1: Using `GridSearchCV`\n",
    "\n",
    "# ■Steps\n",
    "## 1. Load & Preprocess\n",
    " - using `SIUDataPreprocess`\n",
    " - **MUST load labels for testing**  \n",
    " \n",
    "## 2. Find hyperparameters for document embedding\n",
    " - using `D2VInputTransformer`(custom), `D2VTransformer`, `GridSearchCV`\n",
    " - Save `.best_params_` and use later\n",
    " \n",
    "## 3. Pipelining other steps for modeling\n",
    "#### - Keyword Generating\n",
    "- using `KeywordGenerator`(custom)\n",
    "\n",
    "#### - Classifying\n",
    "- using `FeatureUnion` for concatenating two steps above (later)\n",
    "    - There are issues while doing CV,   \n",
    "        because of **t-test for subsetting words according to their correlation with y**\n",
    "- using `xgboost` to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import itertools\n",
    "from time import time\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('util'))))\n",
    "sys.path.append(os.path.dirname(os.path.abspath(os.path.dirname('preprocess'))))\n",
    "from konlpy.tag import Kkma, Komoran\n",
    "import ast\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm_notebook\n",
    "import warnings\n",
    "\n",
    "from gensim.sklearn_api import D2VTransformer\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "# from sklearn.externals import joblib\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score,roc_auc_score\n",
    "import xgboost as xgb\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from preprocess.siu_data_preproc import *\n",
    "from preprocess.text_handling import do_text_ma, make_ngram, add_ngrams_to_ma\n",
    "from document_embedding import *\n",
    "from d2v_input_transformer_2 import D2VInputTransformer\n",
    "from keyword_generator import KeywordGenerator\n",
    "\n",
    "def pickle_save(filename, object_name):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(object_name, f)\n",
    "        \n",
    "def pickle_load(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "        \n",
    "def get_clf_eval(y_test, y_pred):\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    F1 = f1_score(y_test, y_pred)\n",
    "    AUC = roc_auc_score(y_test, y_pred)\n",
    "    print('오차행렬:\\n', confusion)\n",
    "    print('\\n정확도: {:.4f}'.format(accuracy))\n",
    "    print('정밀도: {:.4f}'.format(precision))\n",
    "    print('재현율: {:.4f}'.format(recall))\n",
    "    print('F1: {:.4f}'.format(F1))\n",
    "    print('AUC: {:.4f}'.format(AUC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load & Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "레이블은 추후에 전달받은거라 아래 청크처럼 추가함. \n",
    "- 현재 버전의 전처리와 맞지 않아 코드 검증용으로만 활용, 유효성 낮음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_keyword = 'expanded'\n",
    "tgt_yyyymm = '2021-11-21'\n",
    "data_dir = 'data'\n",
    "\n",
    "doubtful_hospital_list = pd.read_csv('preprocess/hospital_list.csv', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "///////////////////////////////////////////////\n",
      "////////// Data Loading\n",
      "///////////////////////////////////////////////\n",
      "data/blog_contents_백내장+숙소_from2020-11-21_to2021-11-21_expanded.csv\n",
      "백내장+숙소: (121, 6)\n",
      "data/blog_contents_백내장+수당_from2020-11-21_to2021-11-21_expanded.csv\n",
      "백내장+수당: (108, 6)\n",
      "data/blog_contents_백내장+할인_from2020-11-21_to2021-11-21_expanded.csv\n",
      "백내장+할인: (1959, 6)\n",
      "data/blog_contents_백내장+호텔_from2020-11-21_to2021-11-21_expanded.csv\n",
      "백내장+호텔: (554, 6)\n",
      "data/blog_contents_백내장+실비_from2020-11-21_to2021-11-21_expanded.csv\n",
      "백내장+실비: (1332, 6)\n",
      "data/blog_contents_백내장+실손_from2020-11-21_to2021-11-21_expanded.csv\n",
      "백내장+실손: (1575, 6)\n",
      "data/blog_contents_백내장+페이백_from2020-11-21_to2021-11-21_expanded.csv\n",
      "백내장+페이백: (58, 6)\n",
      "data/blog_contents_백내장+부수입_from2020-11-21_to2021-11-21_expanded.csv\n",
      "백내장+부수입: (7, 6)\n",
      "data/blog_contents_백내장+소개_from2020-11-21_to2021-11-21_expanded.csv\n",
      "백내장+소개: (8330, 6)\n",
      "====== successfully done\n",
      "///////////////////////////////////////////////\n",
      "////////// Date column processing\n",
      "///////////////////////////////////////////////\n",
      "====== successfully done\n",
      "///////////////////////////////////////////////\n",
      "////////// Combining to dataframe\n",
      "///////////////////////////////////////////////\n",
      "Raw table---------------------\n",
      "(14044, 6)\n",
      "After filtering---------------\n",
      "(10774, 6)\n",
      "===== successfully done\n",
      "///////////////////////////////////////////////\n",
      "////////// Extracting hashtags\n",
      "///////////////////////////////////////////////\n",
      "====== successfully done\n",
      "///////////////////////////////////////////////\n",
      "////////// Data seperation; by hospital or not\n",
      "///////////////////////////////////////////////\n",
      "Original:  (10774, 7)\n",
      "Blog written by hospital:  (2988, 7)\n",
      "Blog written by personal:  (7729, 7)\n",
      "====== successfully done\n"
     ]
    }
   ],
   "source": [
    "### Preprocessing chunk\n",
    "\n",
    "preprocessor = SIUDataPreprocess(target_keyword=tgt_keyword,\n",
    "                                 target_yyyymm=tgt_yyyymm,\n",
    "                                 data_directory=data_dir,\n",
    "                                 text_columns=['name', 'title', 'content'])\n",
    "\n",
    "preprocessor.load_data_dict()\n",
    "preprocessor.transform_date()\n",
    "preprocessor.combine_data_dict()\n",
    "preprocessor.extract_hashtags(content_col='content', \n",
    "                              hospital_re_target='.*(안과|병원|의원)$')\n",
    "\n",
    "data_hospital, data_prsnl = preprocessor.hospital_prsnl_split(hospital_words_list=['병원', '의원', '외과', '안과'],\n",
    "                                                        non_word_list=['동물', '동물병원'])\n",
    "\n",
    "\n",
    "# ## 병원명 관련 과정 // 'hospital_list.csv'가 없다면 생략 가능\n",
    "# hospital_names = preprocessor.extract_hospital_name('.*(안과|병원|의원).*').rename('hospital_name')\n",
    "# doubtful_hospital_names = preprocessor.match_doubtful_hospitals(hospital_names, \n",
    "#                                                              doubtful_hospital_list['병원명'], \n",
    "#                                                              0.7).rename('doubtful_hospital_name')\n",
    "\n",
    "# data_hospital_2 = pd.concat([data_hospital, hospital_names, doubtful_hospital_names], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2988, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hospital.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('siu_백내장_label_ver1.txt', header=None)[:data_hospital.shape[0]]\n",
    "\n",
    "data_hospital['label'] = labels.astype(int).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    699\n",
       "1.0    114\n",
       "2.0     21\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hospital['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Find hyperparameters for document embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2566\n",
       "1.0     114\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hospital = data_hospital.loc[data_hospital['content'].map(lambda x: '동물병원' not in x)]\n",
    "data_hospital = data_hospital.loc[data_hospital['label'].map(lambda x: x!=2)].reset_index(drop=True)\n",
    "data_hospital['label'] = data_hospital['label'].fillna(0)\n",
    "data_hospital['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2626, 8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Trimming 1% from each side w.r.t. length of content\n",
    "trim_thresh = .01\n",
    "quantile_lower = data_hospital['content'].apply(len).quantile(0 + trim_thresh)\n",
    "quantile_upper = data_hospital['content'].apply(len).quantile(1 - trim_thresh)\n",
    "\n",
    "data_hospital = data_hospital.loc[(data_hospital['content'].apply(len) > quantile_lower) \\\n",
    "                            & (data_hospital['content'].apply(len) < quantile_upper)].reset_index(drop=True)\n",
    "data_hospital.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.9 s, sys: 361 ms, total: 16.2 s\n",
      "Wall time: 5.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X = data_hospital['content']\n",
    "y = data_hospital['label']\n",
    "\n",
    "tagger = Komoran()\n",
    "pos_list = ('NNG', 'NNP', 'NP', 'VV', 'VA')\n",
    "stopwords = []\n",
    "\n",
    "# X_ma = do_text_ma(X, tagger, pos_list, stopwords, is_morph='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "# pickle_save('X_ma.pkl', X_ma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "X_ma = pickle_load('X_ma.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set pipeline for d2v hyperparameters\n",
    "ngram_names = ['content_1gram_1', 'content_2gram', 'content_3gram']\n",
    "ngram_ns = [1,2,3]\n",
    "how_ngram = '1_2_3'\n",
    "\n",
    "pipeline_d2v = Pipeline([\n",
    "                            ('preproc', D2VInputTransformer(ngram_names, ngram_ns, how_ngram)),\n",
    "                            ('embed', D2VTransformer()),\n",
    "                            ('clf', xgb.XGBClassifier(eval_metric = 'logloss'))\n",
    "                        ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_hospital['content'].map(lambda x: x.strip()=='').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# ## Set parameters and do CV\n",
    "\n",
    "# parameters_d2v = {\n",
    "#     'embed__window' : [5,6,7]\n",
    "# }\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_ma, y)\n",
    "\n",
    "# # X_train = X_train.reset_index(drop=True) \n",
    "# # y_train = y_train.reset_index(drop=True) \n",
    "\n",
    "# cv_d2v = GridSearchCV(pipeline_d2v, parameters_d2v)\n",
    "# cv_d2v.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Check the best parameters and save\n",
    "\n",
    "# print(cv_d2v.best_params_)\n",
    "# best_params_d2v = cv_d2v.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 결정된 `best_params_d2v` 적용 및 Embedding 진행 후 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline_d2v_final = Pipeline([\n",
    "#                                 ('preproc', D2VInputTransformer(ngram_names, ngram_ns, how_ngram)),\n",
    "#                                 ('embed', D2VTransformer())\n",
    "#                             ])\n",
    "\n",
    "# pipeline_d2v_final.set_params(**best_params_d2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# doc_embedded_vector = pipeline_d2v_final.fit_transform(X_ma)\n",
    "# pickle_save('doc_embedded_vector.pkl', doc_embedded_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "doc_embedded_vector = pickle_load('doc_embedded_vector.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Pipelining 3 steps for modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# keyword_gen = KeywordGenerator(ngram_names, ngram_ns, y)\n",
    "\n",
    "# keyword_based_df = keyword_gen.fit_transform(X_ma)\n",
    "# keyword_based_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save\n",
    "# pickle_save('keyword_based_df.pkl', keyword_based_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load\n",
    "# keyword_based_df = pickle_load('keyword_based_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_embedded_df = pd.DataFrame(doc_embedded_vector)\n",
    "# doc_embedded_df.columns = ['embed_{}'.format(x) for x in range(doc_embedded_df.shape[1])]\n",
    "# doc_embedded_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "# pickle_save('doc_embedded_df.pkl', doc_embedded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load\n",
    "# doc_embedded_df = pickle_load('doc_embedded_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Make training and test set for classifying\n",
    "# X_fin = pd.concat([keyword_based_df, doc_embedded_df], axis=1)\n",
    "\n",
    "# X_fin_train, X_fin_test, y_train, y_test = train_test_split(X_fin, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save\n",
    "# pickle_save('X_fin.pkl', X_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "X_fin = pickle_load('X_fin.pkl')\n",
    "\n",
    "X_fin_train, X_fin_test, y_train, y_test = train_test_split(X_fin, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_clf = Pipeline([\n",
    "    ('clf', xgb.XGBClassifier(eval_metric = 'logloss'))\n",
    "])\n",
    "\n",
    "# pipeline_clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 33s, sys: 104 ms, total: 1min 33s\n",
      "Wall time: 23.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('clf',\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      enable_categorical=False,\n",
       "                                                      eval_metric='logloss',\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type=None,\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      missing=nan,\n",
       "                                                      monotone_constraints=None,\n",
       "                                                      n_estimators=100,\n",
       "                                                      n_jobs=None,\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      predictor=None,\n",
       "                                                      random_state=None,\n",
       "                                                      reg_alpha=None,\n",
       "                                                      reg_lambda=None,\n",
       "                                                      scale_pos_weight=None,\n",
       "                                                      subsample=None,\n",
       "                                                      tree_method=None,\n",
       "                                                      validate_parameters=None,\n",
       "                                                      verbosity=None))]),\n",
       "             param_grid={'clf__n_estimators': [100, 110, 120]})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "parameters_clf = {\n",
    "    'clf__n_estimators': [100, 110, 120]\n",
    "}\n",
    "\n",
    "cv_clf = GridSearchCV(pipeline_clf, parameters_clf)\n",
    "cv_clf.fit(X_fin_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('clf',\n",
       "                 XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                               colsample_bylevel=1, colsample_bynode=1,\n",
       "                               colsample_bytree=1, enable_categorical=False,\n",
       "                               eval_metric='logloss', gamma=0, gpu_id=-1,\n",
       "                               importance_type=None, interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=120,\n",
       "                               n_jobs=4, num_parallel_tree=1, predictor='auto',\n",
       "                               random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                               scale_pos_weight=1, subsample=1,\n",
       "                               tree_method='exact', validate_parameters=1,\n",
       "                               verbosity=None))])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_clf = cv_clf.best_estimator_\n",
    "best_model_clf.fit(X_fin_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "오차행렬:\n",
      " [[619   9]\n",
      " [ 25   4]]\n",
      "\n",
      "정확도: 0.9482\n",
      "정밀도: 0.3077\n",
      "재현율: 0.1379\n",
      "F1: 0.1905\n",
      "AUC: 0.5618\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_model_clf.predict(X_fin_test)\n",
    "\n",
    "get_clf_eval(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "# pickle_save('y_pred.pkl', y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load\n",
    "# y_pred = pickle_load('y_pred.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making Data for Visualization in Quick Sight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.S3Manager import S3Manager\n",
    "s3_mng = S3Manager()\n",
    "\n",
    "s3_vis_dir = 'nylon-detector/visualization/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Related to keyword frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1-1. Simple frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_num</th>\n",
       "      <th>가격</th>\n",
       "      <th>가까이</th>\n",
       "      <th>가깝</th>\n",
       "      <th>가입</th>\n",
       "      <th>가족</th>\n",
       "      <th>감수</th>\n",
       "      <th>감언이설</th>\n",
       "      <th>감염</th>\n",
       "      <th>강하</th>\n",
       "      <th>...</th>\n",
       "      <th>해당</th>\n",
       "      <th>해외</th>\n",
       "      <th>현명</th>\n",
       "      <th>혜택</th>\n",
       "      <th>홍채</th>\n",
       "      <th>확인</th>\n",
       "      <th>활용</th>\n",
       "      <th>후기</th>\n",
       "      <th>후반</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 297 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_num  가격  가까이  가깝  가입  가족  감수  감언이설  감염  강하  ...  해당  해외  현명  혜택  홍채  \\\n",
       "0        3   0    0   0   0   1   0     0   1   0  ...   0   0   0   0   0   \n",
       "1        4   0    0   0   0   0   0     0   0   0  ...   0   0   0   2   0   \n",
       "2       14   1    0   0   0   0   0     0   0   0  ...   0   0   0   0   0   \n",
       "\n",
       "   확인  활용  후기  후반  y_pred  \n",
       "0   0   0   0   0     0.0  \n",
       "1   0   0   0   0     0.0  \n",
       "2   0   0   0   0     0.0  \n",
       "\n",
       "[3 rows x 297 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = X_fin_test.columns[:295]\n",
    "\n",
    "data_keywords_vis = pd.concat([X_fin_test.iloc[:, :295].reset_index(drop=False).rename(columns={'index': 'doc_num'}), pd.Series(y_pred).rename('y_pred')], axis=1)\n",
    "data_keywords_vis = data_keywords_vis.sort_values('doc_num').reset_index(drop=True)\n",
    "data_keywords_vis.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_keywords(data):\n",
    "    for i, keyword in enumerate(keywords):\n",
    "        if i==0:\n",
    "            result = pd.concat([\n",
    "                data['doc_num'],\n",
    "                pd.Series([keyword]*data.shape[0]).rename('term'),\n",
    "                data[keyword].rename('term_cnt'),\n",
    "                data['y_pred'].rename('pred_yn')\n",
    "            ], axis=1)\n",
    "        else:\n",
    "            to_add = pd.concat([\n",
    "                data['doc_num'],\n",
    "                pd.Series([keyword]*data.shape[0]).rename('term'),\n",
    "                data[keyword].rename('term_cnt'),\n",
    "                data['y_pred'].rename('pred_yn')\n",
    "            ], axis=1)\n",
    "            \n",
    "            result = pd.concat([result, to_add], axis=0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_num</th>\n",
       "      <th>term</th>\n",
       "      <th>term_cnt</th>\n",
       "      <th>pred_yn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>가격</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>가격</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>가격</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>가격</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>가격</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_num term  term_cnt  pred_yn\n",
       "0        3   가격         0      0.0\n",
       "1        4   가격         0      0.0\n",
       "2       14   가격         1      0.0\n",
       "3       22   가격         2      0.0\n",
       "4       25   가격         0      0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_keywords_vis_2 = reshape_keywords(data_keywords_vis)\n",
    "data_keywords_vis_2.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to local directory\n",
    "data_keywords_vis_2.to_csv('visualize_data_1_keywords.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-01 04:06:10,952 - root - INFO - upload : visualize_data_1_keywords.csv to Target: nylon-detector/visualization/visualize_data_1_keywords.csv Success.\n"
     ]
    }
   ],
   "source": [
    "# upload to s3\n",
    "s3_mng.upload_file('visualize_data_1_keywords.csv', f'{s3_vis_dir}visualize_data_1_keywords.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. Percentage grouped by `y_pred`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_num</th>\n",
       "      <th>term</th>\n",
       "      <th>term_cnt</th>\n",
       "      <th>pred_yn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>가격</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>가격</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>가격</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>가격</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>가격</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>2583</td>\n",
       "      <td>후반</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>653</th>\n",
       "      <td>2597</td>\n",
       "      <td>후반</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>2604</td>\n",
       "      <td>후반</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>655</th>\n",
       "      <td>2614</td>\n",
       "      <td>후반</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>656</th>\n",
       "      <td>2625</td>\n",
       "      <td>후반</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>193815 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     doc_num term  term_cnt  pred_yn\n",
       "0          3   가격         0      0.0\n",
       "1          4   가격         0      0.0\n",
       "2         14   가격         1      0.0\n",
       "3         22   가격         1      0.0\n",
       "4         25   가격         0      0.0\n",
       "..       ...  ...       ...      ...\n",
       "652     2583   후반         0      0.0\n",
       "653     2597   후반         0      0.0\n",
       "654     2604   후반         0      0.0\n",
       "655     2614   후반         0      0.0\n",
       "656     2625   후반         0      0.0\n",
       "\n",
       "[193815 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_keywords_vis_bool = data_keywords_vis_2.copy()\n",
    "data_keywords_vis_bool['term_cnt'] = data_keywords_vis_bool['term_cnt'].map(lambda x: 1 if x!=0 else 0)\n",
    "data_keywords_vis_bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_y = data_keywords_vis_bool.loc[data_keywords_vis_bool['pred_yn']==1].groupby(['term'])\n",
    "grouped_n = data_keywords_vis_bool.loc[data_keywords_vis_bool['pred_yn']==0].groupby(['term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>pred_y_avg</th>\n",
       "      <th>pred_n_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>가격</td>\n",
       "      <td>53.85</td>\n",
       "      <td>11.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>가까이</td>\n",
       "      <td>15.38</td>\n",
       "      <td>2.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>가깝</td>\n",
       "      <td>46.15</td>\n",
       "      <td>23.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>가입</td>\n",
       "      <td>69.23</td>\n",
       "      <td>6.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>가족</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>홍채</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>확인</td>\n",
       "      <td>61.54</td>\n",
       "      <td>32.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>활용</td>\n",
       "      <td>15.38</td>\n",
       "      <td>9.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>후기</td>\n",
       "      <td>7.69</td>\n",
       "      <td>5.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>후반</td>\n",
       "      <td>38.46</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>295 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    term  pred_y_avg  pred_n_avg\n",
       "0     가격       53.85       11.80\n",
       "1    가까이       15.38        2.17\n",
       "2     가깝       46.15       23.14\n",
       "3     가입       69.23        6.37\n",
       "4     가족        0.00       13.66\n",
       "..   ...         ...         ...\n",
       "290   홍채        0.00        4.66\n",
       "291   확인       61.54       32.30\n",
       "292   활용       15.38        9.01\n",
       "293   후기        7.69        5.28\n",
       "294   후반       38.46        2.33\n",
       "\n",
       "[295 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_y_pcntg = round(100 * grouped_y.sum()['term_cnt'] / grouped_y.count()['term_cnt'], 2).rename('pred_y_avg')\n",
    "grouped_n_pcntg = round(100 * grouped_n.sum()['term_cnt'] / grouped_n.count()['term_cnt'], 2).rename('pred_n_avg')\n",
    "\n",
    "total_pcntg = pd.concat([grouped_y_pcntg, grouped_n_pcntg], axis=1).reset_index()\n",
    "total_pcntg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to local directory\n",
    "total_pcntg.to_csv('visualize_data_2_percentage.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-12-01 04:06:11,380 - root - INFO - upload : visualize_data_2_percentage.csv to Target: nylon-detector/visualization/visualize_data_2_percentage.csv Success.\n"
     ]
    }
   ],
   "source": [
    "# upload to s3\n",
    "s3_mng.upload_file('visualize_data_2_percentage.csv', f'{s3_vis_dir}visualize_data_2_percentage.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_words_list=['병원', '의원', '외과', '안과']\n",
    "hospital_re_target = '.*(안과|병원|의원).*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. name, title, #s로부터 병원의심단어 추출해 pd.Series 만들기\n",
    "hospitals_dict = dict()\n",
    "\n",
    "for i in range(data_hospital.shape[0]):\n",
    "    hospitals_dict[i] = []  # list로 만들거\n",
    "\n",
    "    name = data_hospital['name'][i]\n",
    "    if np.sum([x in name for x in hospital_words_list]) != 0:\n",
    "        hospitals_dict[i].append(name)\n",
    "\n",
    "    title = data_hospital['title'][i]\n",
    "    if np.sum([x in title for x in hospital_words_list]) != 0:\n",
    "        hospitals_dict[i].append(title)\n",
    "\n",
    "    hashs = data_hospital['#s'].map(\n",
    "        lambda x: [tag for tag in x if np.sum([word in tag for word in hospital_words_list]) != 0])[i]\n",
    "    hospitals_dict[i] += hashs\n",
    "\n",
    "hospitals_series = pd.Series(hospitals_dict).map(lambda x: [y.replace('#', '') for y in x])\n",
    "\n",
    "# 2. 한 번 더 검토하며 병원이름 추가 & 정제하기\n",
    "hospitals_series = hospitals_series.map(lambda x: [y if (bool(re.search(hospital_re_target, y))) else None for y in x])\n",
    "hospitals_series = hospitals_series.map(lambda x: list(filter(None.__ne__, x)))\n",
    "hospitals_series = hospitals_series.map(lambda x: [[y for y in z.split() if re.match(hospital_re_target, y)!=None] for z in x])\n",
    "hospitals_series = hospitals_series.map(lambda x: list(itertools.chain.from_iterable(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   [안과의]\n",
       "1                                   [빛소망안과의원, 여의도안과국가유공자]\n",
       "2                                         [빛소망안과의원, 보훈병원]\n",
       "3       [광주안과동그라미빌딩, 광주안과, 동그라미광주안과, 광천동안과, 상무지구안과, 목포...\n",
       "4                                          [김해서울안과, 서울안과]\n",
       "                              ...                        \n",
       "2621                                       [푸른세상안과, 안양안과]\n",
       "2622        [서울대입구역안과, 청안과를, 청안과, 서울대입구역안과, 관악구안과, 봉천동안과]\n",
       "2623                                      [푸른세상안과, 안양안과를]\n",
       "2624                                          [우리안과소개합니다]\n",
       "2625                                           [밝은세상안과에서]\n",
       "Length: 2626, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hospitals_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_keywords_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
